{
  "generatedAt": "2026-02-04T05:12:05.315Z",
  "projects": [
    {
      "id": "aed-sheets",
      "slug": "aed-sheets",
      "name": "AED-Sheets",
      "githubUrl": "https://github.com/Volpestyle/AED-Sheets",
      "oneLiner": "During a NPR internship, I built a MEAN-stack incident logging and tracking app. It includes automatic NPR employee account creation, flexible log search, and per-user plus global subscriptions with email/SMS alerts.",
      "description": "Audio Engineering Discrepancy Logger modernizes NPR's internal incident tooling using MongoDB, Express JS, Angular, and Node.js. It supports log creation, searching by criteria, automatic IT ticket creation, and subscriptions that notify users when logs matching certain criteria are submitted. Documentation of the implementation was exported to PDF and stored in the repo from Confluence.",
      "bullets": [
        "Implemented automatic NPR employee account creation",
        "Built flexible log creation and search features to filter logs by multiple criteria",
        "Implemented personal subscriptions with email or text notifications when matching logs are submitted",
        "Implemented a global subscription mechanism for multiple users to subscribe collectively",
        "Implemented automatic IT ticket creation from qualifying logs"
      ],
      "impactSummary": "Delivered a modern NPR internal tool enabling efficient incident logging, search, notifications, and automatic ticketing for multi-user workflows.",
      "sizeOrScope": "Internal NPR tooling used by NPR staff; supports multi-user/global subscriptions and notification features at scale.",
      "techStack": [
        "MongoDB",
        "Express JS",
        "Angular",
        "Node.js",
        "Web",
        "Node.js (runtime)",
        "Confluence",
        "PDF documentation (export)"
      ],
      "languages": [
        "TypeScript",
        "HTML",
        "JavaScript",
        "SCSS",
        "CSS"
      ],
      "tags": [
        "Web application",
        "Logging",
        "Incident tracking",
        "IT ticketing",
        "Subscription management",
        "MEAN stack",
        "NPR",
        "MongoDB",
        "Mongo",
        "Express JS",
        "Express",
        "ExpressJS",
        "Angular",
        "AngularJS",
        "Node JS",
        "Node.js",
        "Node",
        "MEAN",
        "Confluence",
        "PDF documentation (export)"
      ],
      "context": {
        "type": "work",
        "organization": "National Public Radio (NPR)",
        "role": "Web software developer intern",
        "timeframe": {
          "start": "2019-01-01",
          "end": "2019-01-01"
        }
      },
      "contextType": "work",
      "readme": "# Audio Engineering Discrepancy Logger\nIn summer 2019 I interned at National Public Radio (NPR) as a web software developer, and ended up getting the opportunity to build them a whole new web app on a MEAN stack! (MongoDB, Express JS, Angular, Node JS)\n## Description\nAudio engineers at NPR like to keep track of all technical difficulties that are encountered during production. Before my\ntime at NPR, the system in place to log incidents was running on an outdated tech-stack and wasn't as elegant as many of the users would have liked. During my internship, it was my job to update and redesign this system to be more capable and user-friendly.\n\nSome of the main features included:\n- Automatic account creation for NPR employees.\n- Searching for logs that fit various criteria.\n- Log creation.\n- Personal subscriptions that send email or text notifications to a specific user when a log that fits certain critiera is submitted.\n- Global subscription that many users can subscribe to at once\n- Automatic I.T. ticket creation.\n- User roles (Administrative abilites, ability to create global subscription, etc.)\n\nThe full documentation of my implementation that I shared with my team can be found in pdf form inside this repo. (It was written in Confluence and upon \nexport has experienced some small formatting errors)\n\n## Screenshots\n![search](/screenshots/AED-sheets_screenshot1.png)\n![profile](/screenshots/AED-sheets_screenshot2.png)\n![manage lookups](/screenshots/AED-sheets_screenshot3.png)",
      "embeddingId": "aed-sheets"
    },
    {
      "id": "ai-kit",
      "slug": "ai-kit",
      "name": "ai-kit",
      "githubUrl": "https://github.com/Volpestyle/ai-kit",
      "oneLiner": "Provider-agnostic inference toolkit for Node.js, Go, and Python that standardizes model listings, routing, and streaming across OpenAI, Anthropic, Gemini, Bedrock, xAI, and Ollama.",
      "description": "ai-kit ships shared metadata scraped per provider plus manual catalogs, a reference OpenAPI spec for HTTP servers, and SDKs with HTTP handlers across Node.js, Go, and Python. It includes Ollama local integration and a Grok voice agent with a real-time WebSocket protocol, plus streaming via SSE for progressive UI rendering. It also features an auto-select cheapest compatible model via ModelRouter.",
      "bullets": [
        "Provider-agnostic tooling covering listing, routing, generation, and streaming across OpenAI, Anthropic, Google Gemini, Amazon Bedrock, xAI, and Ollama.",
        "Two sources of model metadata: scraped provider data and manually curated catalogs.",
        "OpenAPI reference at servers/openapi.yaml and cross-language SDKs/HTTP handlers for Node.js, Go, and Python.",
        "Ollama local integration and Grok voice agent (SDK-only) with real-time WebSocket protocol.",
        "Streaming support via SSE for progressive UI rendering."
      ],
      "impactSummary": "Enables rapid, cross-provider experimentation with a consistent API surface, live streaming, and cost-aware routing across OpenAI, Anthropic, Gemini, Bedrock, xAI, and Ollama.",
      "sizeOrScope": "Solo open-source project with Node.js, Go, and Python SDKs; supports six providers plus Ollama; designed for developers building multi-provider AI apps.",
      "techStack": [
        "Node.js",
        "Go",
        "Python",
        "OpenAPI (Swagger)",
        "pnpm",
        "WebSocket",
        "Server-Sent Events (SSE)",
        "HTTP",
        "Ollama",
        "Grok voice agent",
        "ModelRouter",
        "OpenAI",
        "Anthropic",
        "Google Gemini",
        "Amazon Bedrock",
        "xAI"
      ],
      "languages": [
        "Python",
        "TypeScript",
        "Go"
      ],
      "tags": [
        "provider-agnostic",
        "multi-language",
        "SDK",
        "OpenAPI",
        "streaming",
        "SSE",
        "WebSocket",
        "cost-estimation",
        "model-metadata",
        "Ollama",
        "Grok",
        "ai-kit",
        "OpenAI",
        "Anthropic",
        "Google Gemini",
        "Amazon Bedrock",
        "xAI",
        "Node.js",
        "NodeJS",
        "Go",
        "Golang",
        "OpenAI API",
        "Anthropic API",
        "Gemini",
        "Gemini Pro",
        "Bedrock",
        "Grok voice agent",
        "Ollama Local",
        "Swagger",
        "Server-Sent Events",
        "WS",
        "pnpm",
        "HTTP API",
        "HTTP",
        "Server-Sent Events (SSE)"
      ],
      "context": {
        "type": "personal",
        "organization": "Volpestyle",
        "role": "Creator/Maintainer of ai-kit",
        "timeframe": {
          "start": "2025-10-26",
          "end": "2026-01-09"
        }
      },
      "contextType": "personal",
      "readme": "# ai-kit\n\nProvider-agnostic inference tooling for Node.js, Go, and Python. The repo standardizes model\nlisting, routing, generation, streaming (SSE), realtime voice agents (xAI), and cost estimation\nacross OpenAI, Anthropic, Google Gemini, Amazon Bedrock, xAI, and local Ollama endpoints. It also\nships shared model metadata (scraped per provider + manual catalogs) and a reference OpenAPI spec\nfor HTTP servers.\n\n## Packages\n- `packages/node`: Node.js SDK and HTTP handlers\n- `packages/go`: Go SDK and HTTP handlers\n- `packages/python`: Python SDK + local pipelines for basic vision tasks\n- `models`: shared model metadata (scraped + manual catalogs)\n- `servers/openapi.yaml`: reference HTTP API\n- `docs`: architecture overview and HTTP notes\n\n## Model metadata\nai-kit keeps two sources of model metadata:\n- Scraped provider pricing/capabilities in `models/<provider>/scraped_models.json`\n  (generated via `pnpm refresh:models`).\n- Manually curated catalogs for providers without scrape support\n  (ex: `models/replicate_models.json`, `models/meshy_models.json`), including `family`\n  tags used by pipeline UIs.\n\nScraped metadata is intended to supplement provider `/models` listings with pricing and\ncapabilities, while manual catalogs define which non-scraped models should appear in UIs.\n\n## Quickstart\n### Node.js\n```bash\npnpm install\npnpm --filter @volpestyle/ai-kit-node build\n```\n```ts\nimport { createKit, Provider } from \"@volpestyle/ai-kit-node\";\n\nconst kit = createKit({\n  providers: {\n    [Provider.OpenAI]: { apiKey: process.env.OPENAI_API_KEY ?? \"\" },\n  },\n});\n\nconst output = await kit.generate({\n  provider: Provider.OpenAI,\n  model: \"gpt-4o-mini\",\n  messages: [{ role: \"user\", content: [{ type: \"text\", text: \"Hello\" }] }],\n});\n\nconsole.log(output.text);\n```\n\n### Go\n```bash\ngo get github.com/Volpestyle/ai-kit/packages/go@latest\n```\nReleases are tagged with `packages/go/vX.Y.Z`.\n```go\npackage main\n\nimport (\n  \"context\"\n  \"fmt\"\n  \"os\"\n\n  aikit \"github.com/Volpestyle/ai-kit/packages/go\"\n)\n\nfunc main() {\n  kit, err := aikit.New(aikit.Config{\n    OpenAI: &aikit.OpenAIConfig{APIKey: os.Getenv(\"OPENAI_API_KEY\")},\n  })\n  if err != nil {\n    panic(err)\n  }\n\n  out, err := kit.Generate(context.Background(), aikit.GenerateInput{\n    Provider: aikit.ProviderOpenAI,\n    Model:    \"gpt-4o-mini\",\n    Messages: []aikit.Message{{\n      Role: \"user\",\n      Content: []aikit.ContentPart{{\n        Type: \"text\",\n        Text: \"Hello\",\n      }},\n    }},\n  })\n  if err != nil {\n    panic(err)\n  }\n\n  fmt.Println(out.Text)\n}\n```\n\n### Python\n```bash\npython -m pip install -e packages/python\n```\n```py\nimport os\nfrom ai_kit import Kit, KitConfig, GenerateInput, Message, ContentPart\nfrom ai_kit.providers import OpenAIConfig\n\nkit = Kit(\n    KitConfig(\n        providers={\n            \"openai\": OpenAIConfig(api_key=os.environ.get(\"OPENAI_API_KEY\", \"\"))\n        }\n    )\n)\n\nout = kit.generate(\n    GenerateInput(\n        provider=\"openai\",\n        model=\"gpt-4o-mini\",\n        messages=[Message(role=\"user\", content=[ContentPart(type=\"text\", text=\"Hello\")])],\n    )\n)\n\nprint(out.text)\n```\n\n## Ollama (local)\nOllama speaks the OpenAI-compatible API on `http://localhost:11434`. Configure the\n`ollama` provider without an API key.\n\n### Node.js\n```ts\nimport { createKit, Provider } from \"@volpestyle/ai-kit-node\";\n\nconst kit = createKit({\n  providers: {\n    [Provider.Ollama]: { baseURL: \"http://localhost:11434\" },\n  },\n});\n```\n\n### Go\n```go\nkit, err := aikit.New(aikit.Config{\n  Ollama: &aikit.OllamaConfig{BaseURL: \"http://localhost:11434\"},\n})\n```\n\n### Python\n```py\nfrom ai_kit import Kit, KitConfig\nfrom ai_kit.providers import OllamaConfig\n\nkit = Kit(KitConfig(providers={\"ollama\": OllamaConfig(base_url=\"http://localhost:11434\")}))\n```\n\n## Examples\n### Auto-select the cheapest compatible model\n```ts\nimport { ModelRouter, Provider } from \"@volpestyle/ai-kit-node\";\n\nconst models = await kit.listModelRecords();\nconst router = new ModelRouter();\nconst resolved = router.resolve(models, {\n  constraints: { requireTools: true, maxCostUsd: 2.0 },\n  preferredModels: [\"openai:gpt-4o-mini\"],\n});\n\nconst output = await kit.generate({\n  provider: resolved.primary.provider,\n  model: resolved.primary.providerModelId,\n  messages: [{ role: \"user\", content: [{ type: \"text\", text: \"Summarize this\" }] }],\n});\n```\n\n### Stream SSE for progressive UI rendering (Node)\n```ts\nimport express from \"express\";\nimport { createKit, httpHandlers, Provider } from \"@volpestyle/ai-kit-node\";\n\nconst app = express();\napp.use(express.json());\n\nconst kit = createKit({\n  providers: {\n    [Provider.OpenAI]: { apiKey: process.env.OPENAI_API_KEY ?? \"\" },\n  },\n});\n\nconst handlers = httpHandlers(kit);\napp.post(\"/generate\", handlers.generate());\napp.post(\"/generate/stream\", handlers.generateSSE());\napp.get(\"/provider-models\", handlers.models());\n\napp.listen(3000);\n```\n\n### Grok voice agent (SDK-only)\nxAI voice agents are exposed via the SDKs, mapping to the realtime WebSocket API.\nSee `docs/grok-voice-agent-api.md` for protocol details and `packages/*/README.md`\nfor usage examples.\n\nMore details live in `docs/README.md`. Testing fixtures are documented in `docs/testing.md`.",
      "embeddingId": "ai-kit"
    },
    {
      "id": "aws-iam-projects",
      "slug": "aws-iam-projects",
      "name": "AWS-IAM-Projects",
      "githubUrl": "https://github.com/Volpestyle/AWS-IAM-Projects",
      "oneLiner": "Prototyped a new AWS IAM Console UX with a React/TypeScript frontend, using Polaris and IAM APIs to showcase the Users entity redesign.",
      "description": "This project documents a UX mock for a React-based IAM Console, built as part of the AWS IAM Console team's Console Redesign initiative. It leverages Polaris (AWS's internal UI framework) alongside IAM APIs to render a Users entity workflow, including a user details page demo and related visuals. The work demonstrates frontend design and prototyping for an enterprise IAM console and serves as a portfolio reference for React/TypeScript implementations using Polaris.",
      "bullets": [
        "Built a UX mock for the IAM Console's Users entity using React + TypeScript.",
        "Leveraged Polaris (internal UI framework) with IAM APIs to simulate real data flows.",
        "Created a demo illustrating core features of the Users entity and a user details page (includes a screenshot).",
        "Aligned the mock with the Console Redesign effort to inform frontend design decisions for IAM UI.",
        "Provides documentation and visuals to showcase the approach in a portfolio context."
      ],
      "impactSummary": "Demonstrates how Polaris-based UI can be paired with IAM APIs to prototype a redesigned IAM Console focused on the Users entity, informing frontend design directions for enterprise IAM work.",
      "sizeOrScope": "Single-developer prototype within the AWS IAM Console team; internal demo illustrating the Users entity at a console-level scale.",
      "techStack": [
        "Polaris (internal UI framework)",
        "React",
        "TypeScript",
        "AWS IAM APIs",
        "Polaris",
        "Web"
      ],
      "languages": [],
      "tags": [
        "IAM",
        "AWS IAM",
        "IAM Console",
        "Polaris",
        "React",
        "UI/UX",
        "Console Redesign",
        "Users UI mock",
        "Identity and Access Management (IAM)",
        "AWS Identity and Access Management",
        "Identity and Access Management",
        "Polaris UI framework",
        "React.js",
        "Polaris (internal UI framework)",
        "AWS IAM APIs"
      ],
      "context": {
        "type": "work",
        "organization": "Amazon Web Services (AWS) - Identity and Access Management Console team",
        "role": "Frontend/UI Prototyper (Console Redesign)",
        "timeframe": {
          "start": "2024-03-30",
          "end": "2024-03-31"
        }
      },
      "contextType": "work",
      "readme": "# AWS Projects\nAn empty repository which exists to provide context around my work at Amazon Web Services on the Identity and Access Management console team. \n\n## AWS Identity and Access Management Console\n### Console Redesign\nUtilized AWS's internal UI framework 'Polaris' along with the AWS IAM APIs to implement a UX mock for a new React-based console. This [demo](https://drive.google.com/file/d/1BNKPGXYAASANI5sNNY7UIebjXBa3zVtN/view?usp=share_link) shows off some of the basic features implemented for the 'Users' entity specifically. Created in React using Typescript.\n\n![The user details page](screenshot.png)",
      "embeddingId": "aws-iam-projects"
    },
    {
      "id": "basic-budget",
      "slug": "basic-budget",
      "name": "basic-budget",
      "githubUrl": "https://github.com/Volpestyle/basic-budget",
      "oneLiner": "A modern, geeky monthly budgeting app with offline PWA support built with SvelteKit and a Go backend on AWS.",
      "description": "Basic Budget is a modern, dark-themed budgeting app focused on personal finance. It supports multiple income streams, transaction logging with categories, tags, and merchants, and automation for recurring payments. The frontend uses SvelteKit, GSAP, and TypeScript, while the backend runs on Go (Lambda) with DynamoDB, all provisioned via AWS CDK and Terraform, and it includes Google Sign-In (OIDC) authentication and full PWA offline support. The repository is organized into apps (web, api), packages (ui, config, types) and infra, with a design-spec.md detailing the architecture and offline strategy.",
      "bullets": [
        "Implemented multi-source income tracking (salary, freelance, rental)",
        "Implemented transaction logging with categories, tags, and merchants",
        "Implemented recurring payments automation",
        "Implemented category budgets with monthly limits and visual progress",
        "Delivered rich analytics: donut charts, bar graphs, and cash flow timelines"
      ],
      "impactSummary": "Delivers a feature-rich, offline-capable personal budgeting experience with visual analytics and recurring payments automation.",
      "sizeOrScope": "Solo project; personal budgeting app with cloud-backed data and offline-first PWA.",
      "techStack": [
        "Frontend: SvelteKit, GSAP, TypeScript",
        "Backend: Go (Lambda)",
        "Database: DynamoDB",
        "Infra: AWS CDK, Terraform",
        "Auth: Google Sign-In (OIDC)",
        "Tooling: pnpm, AWS CLI",
        "SvelteKit",
        "AWS",
        "pnpm",
        "AWS CLI",
        "AWS CDK",
        "Terraform"
      ],
      "languages": [
        "Svelte",
        "TypeScript",
        "Go",
        "Shell",
        "CSS",
        "JavaScript",
        "HTML",
        "Makefile"
      ],
      "tags": [
        "SvelteKit",
        "Go",
        "AWS",
        "DynamoDB",
        "PWA",
        "OIDC",
        "Google Sign-In",
        "Budgeting",
        "Personal Finance",
        "Analytics",
        "Recurring Payments",
        "Offline",
        "Finance",
        "GreenSock",
        "GSAP",
        "AWS Lambda",
        "AWS CDK",
        "Terraform",
        "Amazon DynamoDB",
        "PNPM",
        "AWS CLI",
        "Command Line Interface",
        "Lambda"
      ],
      "context": {
        "type": "personal",
        "organization": "Self-initiated",
        "role": "Developer",
        "timeframe": {
          "start": "2023-01-01",
          "end": "2025-11-28"
        }
      },
      "contextType": "personal",
      "readme": "# Basic Budget\n\nA modern, geeky monthly budgeting app with a sleek dark interface.\n\n## Overview\n\nBasic Budget helps you stay on top of your finances with:\n\n- **Income tracking** — Multiple streams (salary, freelance, rental)\n- **Transaction logging** — Quick capture with categories, tags, and merchants\n- **Recurring payments** — Auto-generated expenses and incomes\n- **Category budgets** — Monthly limits with progress visualization\n- **Rich analytics** — Donut charts, bar graphs, cash flow timelines\n- **PWA support** — Install on any device, works offline\n\n## Tech Stack\n\n| Layer      | Technology                        |\n| ---------- | --------------------------------- |\n| Frontend   | SvelteKit, GSAP, TypeScript       |\n| Backend    | Go (Lambda)                       |\n| Database   | DynamoDB                          |\n| Infra      | AWS CDK / Terraform               |\n| Auth       | Google Sign-In (OIDC)             |\n\n## Project Structure\n\n```\n/\n├─ apps/\n│  ├─ web/           # SvelteKit PWA frontend\n│  └─ api/           # Go serverless backend\n├─ packages/\n│  ├─ ui/            # Shared Svelte components\n│  ├─ config/        # Shared configuration\n│  └─ types/         # Shared TypeScript types\n├─ infra/            # AWS infrastructure (CDK/Terraform)\n└─ design-spec.md    # Full design specification\n```\n\n## Getting Started\n\n### Prerequisites\n\n- Node.js 20+\n- Go 1.21+\n- pnpm\n- AWS CLI (configured)\n\n### Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/your-username/basic-budget.git\ncd basic-budget\n\n# Install dependencies\npnpm install\n\n# Install Go dependencies\ncd apps/api && go mod download && cd ../..\n```\n\n### Development\n\n```bash\n# Start the frontend dev server\npnpm --filter web dev\n\n# Run the API locally\ncd apps/api && go run ./cmd/api\n```\n\n### Build\n\n```bash\n# Build frontend\npnpm --filter web build\n\n# Build API\ncd apps/api && go build -o bin/api ./cmd/api\n```\n\n## Documentation\n\nSee [design-spec.md](design-spec.md) for the full design specification including:\n\n- Data models and DynamoDB schema\n- API endpoints and authentication flow\n- Frontend architecture and state management\n- UI/UX design system\n- PWA and offline strategy\n- Security considerations\n\n## Design\n\n**Theme:** Dark, minimal, geeky\n\n| Element     | Value                    |\n| ----------- | ------------------------ |\n| Background  | `#050816`                |\n| Surface     | `#0B1020`                |\n| Primary     | `#00F5D4` (neon teal)    |\n| Typography  | Inter + JetBrains Mono   |\n\n## License\n\nMIT",
      "embeddingId": "basic-budget"
    },
    {
      "id": "game-asset-pipeline",
      "slug": "game-asset-pipeline",
      "name": "game-asset-pipeline",
      "githubUrl": "https://github.com/Volpestyle/game-asset-pipeline",
      "oneLiner": "I built an AI-powered sprite animation pipeline that converts reference images into consistent, export-ready animations for web and mobile.",
      "description": "A Next.js 15 app with a timeline-based editor that ingests multi-image character references, extracts identity, and generates complete animation frames using AI backends. It supports frame-by-frame interpolation, video-to-frames workflows, and multiple export formats (PNG frames, spritesheets with JSON metadata, and ZIP bundles) tuned for web and React Native/Expo.",
      "bullets": [
        "Implemented Character Identity System: multi-image reference ingestion with identity extraction to ensure consistency across styles.",
        "Developed Animation Configuration: timeline-based editor with text prompts, configurable frame count, and keyframe anchors.",
        "Built Generation Modes: frame-by-frame interpolation (img2img) and video-to-frames generation via OpenAI Sora and Replicate models.",
        "Integrated AI backends and refinements: OpenAI Sora Video API, Replicate models (Ray2, PixVerse v5, ToonCrafter, Veo 3.1/fast) and refinements (rd-fast, rd-plus, nano-banana-pro).",
        "Implemented on-disk Local Storage MVP: storage/characters and storage/animations layout with per-character refs, working specs, and versioned outputs."
      ],
      "impactSummary": "Delivers end-to-end AI-assisted animation creation from reference art to web/mobile exports with a local storage MVP and extensible AI integrations.",
      "sizeOrScope": "Solo project; MVP supports local storage for characters/animations; designed for small teams and local previews; potential to scale to cloud storage.",
      "techStack": [
        "Next.js 15 (App Router)",
        "Tailwind CSS",
        "shadcn/ui",
        "FFmpeg",
        "OpenAI Sora Video API",
        "Replicate (Ray2, PixVerse v5, ToonCrafter, Veo 3.1/fast)",
        "Replicate refinements (rd-fast, rd-plus, nano-banana-pro)",
        "Aseprite JSON",
        "S3-compatible/Local filesystem storage",
        "Expo / React Native",
        "Web",
        "Mobile (React Native/Expo)",
        "OpenAI API",
        "Replicate API",
        "Sora Video API",
        "google Gemini API",
        "Ray2",
        "PixVerse v5",
        "ToonCrafter",
        "Veo 3.1/fast",
        "retro-diffusion/rd-fast",
        "retro-diffusion/rd-plus",
        "google/nano-banana-pro",
        "Flux-2-Max",
        "Aseprite JSON (format)",
        "S3-compatible storage",
        "Local filesystem storage"
      ],
      "languages": [
        "TypeScript",
        "CSS",
        "Python",
        "JavaScript"
      ],
      "tags": [
        "AI-powered animation",
        "sprite pipeline",
        "character identity",
        "timeline editor",
        "frame interpolation",
        "video-to-frames",
        "export formats",
        "spritesheet",
        "local storage MVP",
        "web and mobile export",
        "AI-powered animation pipeline",
        "Sprite/asset generation",
        "Character identity management",
        "Timeline-based animation editor",
        "Video-to-frames and frame interpolation",
        "Sprite export formats (PNG frames, spritesheets, JSON metadata)",
        "Local storage/assets pipeline",
        "Next.js",
        "Next.js 15",
        "Next 15 App Router",
        "Tailwind CSS",
        "shadcn/ui",
        "OpenAI Sora Video API",
        "Sora Video API",
        "OpenAI API",
        "Replicate",
        "Replicate API",
        "Ray2",
        "PixVerse v5",
        "PixVerse",
        "ToonCrafter",
        "Veo 3.1",
        "Veo fast",
        "rd-fast",
        "retro-diffusion/rd-fast",
        "rd-plus",
        "retro-diffusion/rd-plus",
        "nano-banana-pro",
        "google/nano-banana-pro",
        "Flux-2-Max",
        "black-forest-labs/flux-2-max",
        "ffmpeg",
        "Aseprite JSON",
        "Aseprite",
        "S3-compatible storage",
        "Local filesystem storage",
        "Expo",
        "React Native",
        "React Native/Expo",
        "google Gemini API",
        "Veo 3.1/fast",
        "Aseprite JSON (format)"
      ],
      "context": {
        "type": "personal",
        "organization": "Self",
        "role": "Developer/Creator",
        "timeframe": {
          "start": "2024-01-01",
          "end": "2026-02-02"
        }
      },
      "contextType": "personal",
      "readme": "# Game Asset Pipeline\n\nAI-powered sprite animation pipeline for creating consistent character animations from reference images.\n\n## Vision\n\nUpload character reference images → Define animation parameters → Generate complete animation frames using AI → Export for web/mobile.\n\n### Core Workflow\n\n```\n┌─────────────────┐     ┌──────────────────┐     ┌─────────────────┐     ┌──────────────┐\n│  Upload Refs    │ ──▶ │ Create Character │ ──▶ │ Define Animation│ ──▶ │   Generate   │\n│  (concept art)  │     │    Identity      │     │   (timeline)    │     │    Frames    │\n└─────────────────┘     └──────────────────┘     └─────────────────┘     └──────────────┘\n                                                                                 │\n                                                                                 ▼\n                                                                        ┌──────────────┐\n                                                                        │    Export    │\n                                                                        │ (PNG/Sheet)  │\n                                                                        └──────────────┘\n```\n\n## Features\n\n### Character Identity System\n- Upload multiple reference images (concept art, multi-angle views)\n- System extracts character \"identity\" for consistent generation\n- Supports various art styles (pixel art, hand-drawn, 3D rendered, etc.)\n- Character style is injected into the generation prompt\n\n### Animation Configuration\n- Text description of desired animation (\"walk cycle\", \"attack slash\", etc.)\n- Configurable frame count\n- Keyframe support - set specific frames as anchors\n- Timeline-based editor for precise control\n\n### Generation Modes\n1. **Frame-by-frame (img2img)**: Keyframes as anchors, AI interpolates between\n2. **Video-to-frames**: Generate smooth video, extract frames (better for fluid motion)\n\n### Export Options\n- Individual PNG frames\n- Spritesheet + JSON metadata (frame positions, dimensions, timing)\n- ZIP bundle with spritesheet + metadata + frames\n- Ready for web (React) and mobile (React Native/Expo)\n\n## Tech Stack\n\n- **Framework**: Next.js 15 (App Router)\n- **Styling**: Tailwind CSS + shadcn/ui\n- **AI Backend**:\n  - Primary: OpenAI Sora Video API (image → video → frames)\n  - Secondary: Replicate video models (Ray2, PixVerse v5, ToonCrafter, Veo 3.1/fast)\n  - Keyframe refinement: Replicate rd-fast/rd-plus and nano-banana-pro\n- **Storage**: Local filesystem (MVP), S3-compatible (future)\n\n## Project Structure\n\n```\nsrc/\n├── app/                    # Next.js App Router pages\n│   ├── page.tsx           # Home/dashboard\n│   ├── characters/        # Character management\n│   ├── animations/        # Animation editor\n│   └── api/               # API routes\n├── components/\n│   ├── ui/                # shadcn/ui components\n│   ├── character/         # Character-related components\n│   ├── animation/         # Animation editor components\n│   └── export/            # Export functionality\n├── lib/\n│   ├── ai/                # AI provider integrations\n│   │   ├── openai.ts\n│   │   ├── replicate.ts\n│   │   └── soraConstraints.ts\n│   ├── character/         # Character identity logic\n│   ├── animation/         # Animation generation logic\n│   └── export/            # Export utilities (spritesheet, etc.)\n├── types/                 # TypeScript types\n└── hooks/                 # React hooks\n```\n\n## Getting Started\n\n```bash\n# Install dependencies\nnpm install\n\n# Ensure ffmpeg is installed (required for video frame extraction)\n# macOS: brew install ffmpeg\n# Ubuntu: sudo apt-get install ffmpeg\n# Windows: choco install ffmpeg\n\n# Set up environment variables\ncp .env.example .env.local\n# Add your API keys (REPLICATE_API_TOKEN, etc.)\n\n# Run development server\nnpm run dev\n```\n\n## Environment Variables\n\n```\nOPENAI_API_KEY=            # OpenAI API key (Sora video generation)\nREPLICATE_API_TOKEN=       # Replicate API token\nFAL_KEY=                   # Fal.ai API key (planned/unused)\nGOOGLE_AI_API_KEY=         # Gemini API key (planned/unused)\nRD_FAST_MODEL=             # Replicate rd-fast model (optional, defaults to retro-diffusion/rd-fast)\nRD_FAST_VERSION=           # Replicate rd-fast version (optional)\nRD_PLUS_MODEL=             # Replicate rd-plus model (optional, defaults to retro-diffusion/rd-plus)\nRD_PLUS_VERSION=           # Replicate rd-plus version (optional)\nNANO_BANANA_MODEL=         # Replicate nano-banana-pro model (optional, defaults to google/nano-banana-pro)\nNANO_BANANA_VERSION=       # Replicate nano-banana-pro version (optional)\nFLUX_2_MAX_MODEL=          # Replicate flux-2-max model (optional, defaults to black-forest-labs/flux-2-max)\nFLUX_2_MAX_VERSION=        # Replicate flux-2-max version (optional)\nLOG_LEVEL=                 # Log level: debug | info | warn | error (default: info)\nLOG_COLOR=                 # Enable ANSI colors in logs (default: true)\n```\n\n## Local Storage (MVP)\n\nAssets and metadata are stored locally under:\n\n```\nstorage/\n├── characters/{id}/character.json\n├── characters/{id}/references/\n├── characters/{id}/working/            # working reference + spec JSON\n└── animations/{id}/\n    ├── animation.json\n    ├── generation/                     # start/end frame inputs + normalized variants\n    ├── generated/\n    │   ├── frames_raw/                 # extracted frames (pre-loop)\n    │   └── frames/                     # final frames (loop applied)\n    ├── exports/\n    ├── keyframes/\n    └── versions/{versionId}/           # snapshots (generated + keyframes + version.json)\n```\n\nGenerated files are served via `/api/storage/...` for local preview.\n\n## Generation Defaults\n\n### Video-to-Frames (default)\n- Default model: `sora-2`\n- Video size: `720x1280` (sora-2 default). `sora-2-pro` also supports `1024x1792` and `1792x1024`.\n- Duration: 4 seconds\n- Extract FPS: 6\n- Loop mode: loop (end frame = start frame)\n- Frame size derived from character reference (default 253×504)\n- Invalid sizes are automatically coerced to a supported size for the selected model\n- Provider selection is explicit; generation fails if the selected provider's API key is missing\n- Rebuild: you can re-pack spritesheets from `frames_raw` without re-running generation\n\n### Keyframe Refinement\n\nSingle-frame and keyframe refinement use:\n\n- `retro-diffusion/rd-fast` for fast iterations\n- `retro-diffusion/rd-plus` for higher fidelity results\n\nSupported advanced inputs (rd-fast/rd-plus):\n\n- `input_palette` (palette reference image)\n- `tile_x`, `tile_y`\n- `seed`\n- `bypass_prompt_expansion`\n\nOptional refinement model:\n- `google/nano-banana-pro` for general-purpose single-frame refinement\n\n## Export Formats\n\nThe export endpoint produces:\n\n- `spritesheet.png`\n- `spritesheet-array.json` (Aseprite JSON Array)\n- `spritesheet-hash.json` (Aseprite JSON Hash)\n- `frames/` PNG sequence + `frames/index.json` (if spritesheet frames are available)\n- `export_{animationId}.zip` bundle with all export assets\n\n## Roadmap\n\n### Phase 1: Foundation (Current)\n- [x] Project setup and documentation\n- [x] Character upload and management UI\n- [x] Basic character identity storage\n\n### Phase 2: Animation Editor\n- [x] Timeline-based animation configurator\n- [x] Keyframe placement\n- [x] Animation preview\n\n### Phase 3: AI Generation\n- [x] Replicate integration\n- [x] Frame-by-frame generation\n- [x] Video-to-frames generation\n\n### Phase 4: Export & Polish\n- [x] Export to multiple formats\n- [x] Spritesheet generation with metadata\n- [ ] Mobile-ready exports\n\n## Key Concepts\n\n### Character Identity\nA character identity captures the visual essence of a character from reference images. The current pipeline enforces consistency via a working reference canvas and prompt constraints; advanced conditioning (e.g., IP-Adapter) is a possible future enhancement.\n\n### Keyframes\nUser-provided frames that act as \"anchors\" in the animation. The AI generates intermediate frames that smoothly transition between keyframes while maintaining character identity.\n\n### Generation Pipeline\n```\nCharacter Identity + Animation Description + Keyframes\n                          ↓\n              AI Generation (OpenAI/Replicate)\n                          ↓\n                   Raw Generated Frames\n                          ↓\n              Post-processing & Assembly\n                          ↓\n                  Export-ready Assets\n```\n\n## License\n\nMIT",
      "embeddingId": "game-asset-pipeline"
    },
    {
      "id": "ilikeyacut",
      "slug": "ilikeyacut",
      "name": "ilikeyacut",
      "githubUrl": "https://github.com/Volpestyle/ilikeyacut",
      "oneLiner": "A native iOS hairstyling try-on app powered by a Go-based AWS Lambda backend, deployed with AWS SAM templates.",
      "description": "This native mobile monorepo pairs an iOS frontend (Swift) with a Go-based Lambda backend to power hairstyle try-ons using Gemini's nano-banana (Flash Image 2.5). The backend is deployed via AWS SAM templates under a unified deployment workflow. Documentation includes a Design Document, API Contract, iOS token lifecycle, and rate limiting, with a Making-of section featuring a timelapse and a demo GIF.",
      "bullets": [
        "Implemented iOS frontend in Swift for hairstyle try-on",
        "Built serverless backend in Go on AWS Lambda, deployed via SAM templates",
        "Organized a native mobile monorepo integrating Gemini's nano-banana (Flash Image 2.5) with iOS frontend and Go Lambda backend",
        "Documented API contracts, token lifecycle, and rate limiting; included making-of videos and a demo GIF"
      ],
      "impactSummary": "Delivers a complete end-to-end native iOS hairstyling try-on experience backed by a cloud-native Go backend and SAM-based deployment.",
      "sizeOrScope": "Solo project; targets iOS users; monorepo spanning Swift iOS frontend and Go Lambda backend; cloud-native deployment via SAM.",
      "techStack": [
        "Swift iOS frontend",
        "Go-based AWS Lambda backend",
        "AWS Serverless Application Model (SAM) deployment",
        "Gemini's nano-banana (Flash Image 2.5) integration",
        "AWS SAM",
        "iOS",
        "AWS Lambda"
      ],
      "languages": [
        "Swift",
        "Go",
        "Python",
        "Shell",
        "Makefile"
      ],
      "tags": [
        "mobile",
        "beauty-tech",
        "serverless",
        "AWS",
        "iOS",
        "Swift",
        "Go",
        "Golang",
        "Lambda",
        "SAM",
        "Gemini",
        "Nano Banana",
        "monorepo",
        "mobile hairstyling app",
        "beauty tech",
        "cloud-native serverless backend",
        "ios frontend",
        "iPhoneOS",
        "AWS SAM",
        "Serverless Application Model",
        "AWS Lambda",
        "nano-banana",
        "Gemini nano-banana",
        "Flash Image 2.5",
        "Gemini's nano-banana"
      ],
      "context": {
        "type": "personal",
        "organization": "Independent project",
        "role": "Solo developer",
        "timeframe": {
          "start": "2023-01-01",
          "end": "2025-09-10"
        }
      },
      "contextType": "personal",
      "readme": "## ilikeyacut\nNative mobile app monorepo for trying on different hairstyles via Gemini's nano-banana (Flash Image 2.5)\n\n### Stack\n- ios frontend: Swift\n- serverless backend: GO AWS lambdas\n- deployment: [SAM](https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/what-is-sam.html) templates\n\n### Docs\n   - [Design Document](docs/DESIGN.md)\n   - [API Contract](docs/API_CONTRACT.md)\n   - [ios token lifecycle](docs/iOS_TOKEN_LIFECYCLE.md)\n   - [rate limiting](docs/RATE_LIMITING.md)\n\n### Making of\n- [Vibe code timelapse and initial demo](https://www.youtube.com/watch?v=jkfCZ3o19Fc)\n- ![Demo GIF](docs/assets/demo1.gif)",
      "embeddingId": "ilikeyacut"
    },
    {
      "id": "leetclawd",
      "slug": "leetclawd",
      "name": "leetclawd",
      "githubUrl": "https://github.com/Volpestyle/leetclawd",
      "oneLiner": "Leetclawd is a Next.js app that auto-generates coding problems with Claude Code CLI and streams progress live. It verifies solutions against tests and stores problems in a local SQLite DB for offline practice.",
      "description": "A Next.js-based playground that orchestrates Claude Code CLI to produce problem specs, tests, audits, and a verified solution. It streams generation progress via Server-Sent Events as NDJSON from the CLI into the browser, and persists problems and logs to a local SQLite database. Users can chat with Claude about the current problem for hints, and submit their solutions to be tested with a dedicated runner; completed problems appear in a highlighted submission history.",
      "bullets": [
        "Bridged Claude Code CLI with a Next.js route to drive problem generation (spec -> tests -> audit -> solution) and stream NDJSON back to the UI.",
        "Implemented generation status tracking and persisted problem records and logs into SQLite for quick practice access.",
        "Built a chat interface to interact with Claude for hints and guidance and implemented a solution fix reasoning workflow when tests fail.",
        "Created submission flow that runs user solutions through a test runner and surfaces results with syntax-highlighted history."
      ],
      "impactSummary": "Automates end-to-end generation, verification, and persistence of coding problems to enable seamless self-guided practice.",
      "sizeOrScope": "Single-developer project; local SQLite store; streaming progress to a browser-based UI for personal practice.",
      "techStack": [
        "Next.js",
        "Claude Code CLI",
        "SQLite",
        "NDJSON",
        "Server-Sent Events (SSE)",
        "Gson (jar)",
        "lib/test-runner",
        "Node.js",
        "Python (optional)",
        "Java (optional)",
        "NextJS",
        "Web",
        "Browser",
        "Test Runner (lib/test-runner)",
        "Claude Code streaming pattern"
      ],
      "languages": [
        "TypeScript",
        "CSS",
        "JavaScript"
      ],
      "tags": [
        "coding problem generation",
        "education",
        "coding interview prep",
        "algorithm problems",
        "streaming",
        "SSE",
        "SQLite",
        "Claude Code CLI",
        "Next.js",
        "Chat with Claude",
        "coding practice",
        "NextJS",
        "Claude CLI",
        "Claude Code",
        "NDJSON",
        "Server-Sent Events",
        "Gson",
        "Gson jar",
        "Test Runner",
        "lib/test-runner",
        "Server-Sent Events (SSE)",
        "Gson (jar)",
        "Test Runner (lib/test-runner)",
        "Node.js",
        "Python (optional)",
        "Java (optional)",
        "Claude Code streaming pattern"
      ],
      "context": {
        "type": "personal",
        "organization": "Personal project",
        "role": "Developer",
        "timeframe": {
          "start": "2026-01-29",
          "end": "2026-01-29"
        }
      },
      "contextType": "personal",
      "readme": "# leetclawd\n\nLeetclawd is a Next.js app that generates coding problems with the Claude Code CLI, streams progress to the browser, verifies tests against an auto-generated solution, and saves problems to a local SQLite database for practice.\n\n## Architecture overview\n\n```mermaid\nflowchart TD\n  UI[Browser UI] -->|POST /api/generate/stream| Gen[Generate route]\n  Gen -->|spawn CLI| CLI[Claude Code CLI]\n  CLI -->|stream-json NDJSON| Gen\n  Gen -->|SSE events| UI\n  Gen -->|insert| DB[(SQLite)]\n\n  UI -->|POST /api/submit| Submit[Submit route]\n  Submit -->|run tests| Runner[lib/test-runner]\n  Runner -->|results| Submit\n  Submit -->|JSON| UI\n\n  UI -->|POST /api/chat| Chat[Chat route]\n  Chat -->|stream| CLI\n  Chat -->|SSE| UI\n```\n\n## Problem generation pipeline\n\n```mermaid\nsequenceDiagram\n  participant U as User\n  participant UI as App UI\n  participant API as /api/generate/stream\n  participant C as Claude CLI\n  participant T as Test Runner\n  participant DB as SQLite\n\n  U->>UI: Start generation\n  UI->>API: POST (stream)\n  API->>C: Spec -> tests -> audit -> solution\n  API->>T: Run tests\n  API-->>UI: SSE status + delta\n  alt Tests pass\n    API->>DB: Save problem + logs (status: success)\n    API-->>UI: complete\n  else Tests fail\n    API->>DB: Save problem + logs (status: failed)\n    API-->>UI: error\n  end\n```\n\n## Features\n\n- **Problem Generation**: Claude generates problem specs, test cases, audits them, and writes a verified solution\n- **Solution Fix Reasoning**: When solutions fail tests, Claude analyzes failures before retrying\n- **Chat Interface**: Ask Claude questions about the current problem for hints and guidance\n- **Generation Status**: Track whether problems were generated successfully or failed verification\n- **Submission History**: View past successful submissions with syntax highlighting\n\n## Getting started\n\n1. Install dependencies: `npm install`\n2. Run the dev server: `npm run dev`\n3. Open `http://localhost:3000`\n\n## Requirements\n\n- **Claude Code CLI**: Must be installed and authenticated. The app spawns the CLI directly.\n- **Node.js**: Required for the test runner (JS/TS solutions run in vm sandbox)\n- **Python** (optional): For Python problem support\n- **Java** (optional): For Java problem support (uses bundled Gson jar)\n\n## Security notes\n\n- Claude Code CLI can run tools (bash/edit/read) depending on CLI config\n- Do not expose the generation or chat endpoints publicly without restricting tool access\n\n## Documentation\n\n- Architecture and verification flow: `docs/app-architecture.md`\n- Claude Code streaming pattern: `docs/claude-code-streaming.md`\n\n## Repo layout\n\n```\napp/\n  api/\n    generate/stream/  # Problem generation with SSE\n    chat/             # Chat with Claude about problems\n    submit/           # Run user solutions against tests\n    problems/         # List/delete problems\n  problem/            # Problem practice UI\ncomponents/           # React components\nlib/\n  db/                 # SQLite schema and queries\n  claude.ts           # Claude CLI bridge\n  test-runner.ts      # Solution test execution\n  languages.ts        # Language-specific helpers\ndata/                 # SQLite database (gitignored)\nproblems/             # Starter code files (gitignored)\npublic/               # Static assets (3D models, etc.)\ndocs/                 # Architecture documentation\n```",
      "embeddingId": "leetclawd"
    },
    {
      "id": "parse-tree-calculator",
      "slug": "parse-tree-calculator",
      "name": "Parse-Tree-Calculator",
      "githubUrl": "https://github.com/Volpestyle/Parse-Tree-Calculator",
      "oneLiner": "Web-based scientific calculator using a parse-tree expression engine to enforce operator precedence, with tokenization, recursive parentheses handling, and trig support.",
      "description": "Built with HTML, SASS, and vanilla JavaScript, it tokenizes expressions into literals, operators, parentheses, and functions and then builds a parse tree to enforce the order of operations. Parentheses are handled recursively by creating nested subtrees, and a trig-function stack applies sin, cos, or tan to the following literal. The UI accepts input only via on-screen buttons, supports implicit multiplication for opening parentheses while requiring explicit multiplication for trig operations, and allows cursor-based edits anywhere in the input, returning NaN for invalid expressions and logging unclosed parentheses to the console.",
      "bullets": [
        "Tokenization that classifies every piece of the expression as Literal, Operator, Left/Right Parenthesis, or Function.",
        "Parse-tree formation that pushes operators and inserts literals, with right rotations to preserve correct precedence (e.g., expression like 5+2*6).",
        "Recursive parentheses handling by creating new subtrees on open parens and evaluating on close.",
        "Implicit multiplication between opening parentheses (e.g., 5(2+3) = 5*(2+3)).",
        "Explicit multiplication required for trig functions (e.g., 5*sin(3) not 5sin3)."
      ],
      "impactSummary": "Demonstrates parse-tree-based evaluation with tokenization, proper parenthesis handling, and trig support, delivering a functional browser-based scientific calculator.",
      "sizeOrScope": "Solo project; browser-based with an on-screen keypad for individual users.",
      "techStack": [
        "HTML",
        "SASS",
        "Vanilla JavaScript",
        "Web",
        "Browser"
      ],
      "languages": [
        "JavaScript",
        "HTML",
        "SCSS",
        "CSS"
      ],
      "tags": [
        "parse-tree",
        "expression-evaluation",
        "operator-precedence",
        "tokenization",
        "parentheses",
        "trigonometry",
        "sin",
        "cos",
        "tan",
        "implicit-multiplication",
        "on-screen-input",
        "NaN",
        "error-logging",
        "web",
        "parsing",
        "expression evaluation",
        "scientific calculator",
        "mathematics",
        "parse tree",
        "expression tree",
        "tokenizing",
        "tokenize",
        "order of operations",
        "operator precedence",
        "parenthesis handling",
        "opening paren",
        "closing paren",
        "trigonometric functions",
        "implicit multiplication",
        "juxtaposition multiplication",
        "explicit multiplication for trig",
        "multiplication with trig",
        "on-screen buttons",
        "button input",
        "UI keypad",
        "C button",
        "clear input",
        "clear result",
        "negative numbers",
        "unary minus",
        "Not a Number",
        "console log",
        "log to console",
        "console error",
        "HTML",
        "SASS"
      ],
      "context": {
        "type": "personal",
        "organization": "volpestyle",
        "role": "independent developer",
        "timeframe": {
          "start": "2019-02-24",
          "end": "2024-09-03"
        }
      },
      "contextType": "personal",
      "readme": "# Parse-Tree-Calculator\n[Live here](https://volpestyle.github.io/Parse-Tree-Calculator/)   \nA basic scientific calculator built in HTML, SASS, and Vanilla JavaScript.  \n![parse-tree-calc](/doc-images/parse-tree-calc.jpg)\n\n## Usage\nThis calculator can perform all expected operations:\n- Basic Arithmetic\n- Decimals\n- Parenthesis to organize priority\n- Basic trigonometry (sin, cos, tan)\n#### Additonal Information\n- There is implied multiplication between opening parenthesis.  \n(e.g. 5(2+3) will evaluate to 5*(2+3))\n- When using trig functions, there is no implied multiplication, and you must place a '*' sign in between expressions.  \n(e.g., 5\\*sin(3) **not** 5sin3)\n- You can input negative numbers by simply placing a '-' before the number.\n- You can only input expressions with the buttons. \n- If there is data in the input field, the 'C' button will clear only input, otherwise it will clear the result field.\n- You can position the cursor to insert/delete at any place in the input field.\n\n#### Invalid Input\n- Input that cannot be evaluated, such as '2**', will return the user 'NaN'.\n- Input that does not allow the parse tree to be made, such as unclosed parenthesis, will log an error to the console, and return the user nothing.\n\n## Implementation Details\n### Tokenizing\nBefore an expression is evaluated, it must be tokenzed first so 'buildTree()' knows how to build the tree. \nEach component of the expression is typed as either a \"Literal\", \"Operator, \"Left Parenthesis\", \"Right Parenthesis, or \"Function\", and assigned a value. \\\nHere's an example of the token array of '5(sin(5)+2)':\n![token-array](doc-images/token-array.png?raw=true)\n\n### Parse Tree Formation\nThis calculator uses a parse tree to implement order of operations. The tree is built by pushing operators to the top of the tree, while inserting literals to the lowest free node. Below is an example.  \n**Expression: 5+2\\*6**.   \nInsert: '5':\n![parse-tree](doc-images/parse-tree.jpg?raw=true).   \nInsert: '+': \n![parse-tree](doc-images/parse-tree%20(1).jpg?raw=true).   \nInsert: '2': \n![parse-tree](doc-images/parse-tree%20(2).jpg?raw=true).   \nInsert: '\\*': \n![parse-tree](doc-images/parse-tree%20(3).jpg?raw=true).   \nNow you'll notice the order of expressions is incorrect. To fix this, we simply right rotate the tree:\n![parse-tree](doc-images/parse-tree%20(4).jpg?raw=true).    \nInsert '6':\n![parse-tree](doc-images/parse-tree%20(5).jpg?raw=true).   \n  \n#### Parenthesis\nParenthesis are handled by creating a new tree when an an opening parenthesis is found. When a closing parenthesis is found, the tree returned and evaluated, being inserted back into the tree as a number. Since this is done recursively, nested parenthesis work just fine.\n#### Functions\nWhen a trig function is encountered, it is put into a stack. It is popped from the stack when the next literal is encountered, and the result of function and the literal is inserted into the tree.",
      "embeddingId": "parse-tree-calculator"
    },
    {
      "id": "portfolio",
      "slug": "portfolio",
      "name": "portfolio",
      "githubUrl": "https://github.com/Volpestyle/portfolio",
      "oneLiner": "A full-stack portfolio app (live at jcvolpe.me) built with Next.js 15 and React 19, deployed on AWS using OpenNext and CDK. It delivers an AI-powered chat, a full CMS blog, and a GitHub projects viewer with OAuth authentication.",
      "description": "This project is organized as a monorepo with packages for chat data, chat orchestration, GitHub data, and UI components, enabling modular development and testing. The AI chat uses a RAG-based interface with semantic search over portfolio content powered by the OpenAI API; the blog uses DynamoDB for storage with scheduled publishing and an admin dashboard. The GitHub Projects feature renders a dynamic project showcase with docs viewer pulled from GitHub repositories, all secured via NextAuth.js with GitHub and Google OAuth.",
      "bullets": [
        "Implemented a RAG-based AI chat with semantic search over portfolio content.",
        "Built a full CMS/blog with DynamoDB storage, scheduled publishing, and an admin dashboard.",
        "Created a dynamic GitHub Projects viewer with a documentation viewer pulling from GitHub repositories.",
        "Implemented authentication via NextAuth.js with GitHub and Google OAuth.",
        "Deployed infrastructure on AWS (CDK, Lambda@Edge, CloudFront, S3) with OpenNext hosting."
      ],
      "impactSummary": "Demonstrates end-to-end AI chat, content management, and GitHub-backed project documentation on a scalable AWS-based portfolio app.",
      "sizeOrScope": "Independent, solo-project; monorepo with multiplePackages; designed for external visitors (portfolio audience).",
      "techStack": [
        "Next.js 15",
        "React 19",
        "TailwindCSS",
        "Framer Motion",
        "OpenNext",
        "AWS CDK",
        "Lambda@Edge",
        "CloudFront",
        "DynamoDB",
        "S3",
        "Upstash Redis",
        "AWS Secrets Manager",
        "OpenAI API",
        "NextAuth.js",
        "GitHub API",
        "GitHub OAuth",
        "Google OAuth",
        "pnpm",
        "Turbopack",
        "Playwright",
        "Next.js",
        "React",
        "AWS",
        "Node.js"
      ],
      "languages": [
        "TypeScript",
        "JavaScript",
        "Mermaid",
        "CSS"
      ],
      "tags": [
        "AI",
        "RAG",
        "CMS",
        "Blog",
        "GitHub Projects",
        "OAuth",
        "AWS",
        "Next.js",
        "OpenNext",
        "DynamoDB",
        "OpenAI",
        "Docs Viewer",
        "Authentication",
        "AI-powered chat",
        "CMS / Blog",
        "GitHub Projects / Documentation viewer",
        "Authentication / OAuth",
        "Next.js 15",
        "Next 15",
        "NextJS",
        "NextAuth.js",
        "NextAuth",
        "NextAuthJS",
        "TailwindCSS",
        "Tailwind",
        "Framer Motion",
        "Framer",
        "React",
        "ReactJS",
        "OpenAI API",
        "AWS DynamoDB",
        "Lambda@Edge",
        "CloudFront",
        "S3",
        "Upstash Redis",
        "Redis",
        "AWS Secrets Manager",
        "Secrets Manager",
        "AWS CDK",
        "CDK",
        "Playwright",
        "Playwright (E2E)",
        "GitHub API",
        "GitHub OAuth",
        "Google OAuth",
        "pnpm",
        "Turbopack",
        "Node.js"
      ],
      "context": {
        "type": "personal",
        "organization": "Personal project",
        "role": "Full-stack developer and system designer",
        "timeframe": {
          "start": "2024-08-18",
          "end": "2026-01-30"
        }
      },
      "contextType": "personal",
      "readme": "# Portfolio\n\nLive at [jcvolpe.me](https://jcvolpe.me)\n\nA full-stack portfolio application built with Next.js 15, React 19, and deployed on AWS using OpenNext and CDK.\n\n## Features\n\n- **AI-Powered Chat**: RAG-based conversational interface with semantic search over portfolio content\n- **Blog System**: Full CMS with DynamoDB storage, scheduled publishing, and admin dashboard\n- **GitHub Projects**: Dynamic project showcase with documentation viewer from GitHub repos\n- **Authentication**: NextAuth.js with GitHub/Google OAuth\n\n## Tech Stack\n\n| Category | Technologies |\n|----------|-------------|\n| Frontend | Next.js 15, React 19, TailwindCSS, Framer Motion |\n| Backend | Next.js API Routes, NextAuth.js, OpenAI API |\n| Infrastructure | AWS CDK, Lambda@Edge, CloudFront, DynamoDB, S3 |\n| Data | Upstash Redis, AWS Secrets Manager |\n| Testing | Playwright (E2E), Chat Evals |\n\n## Quick Start\n\n```bash\n# Install dependencies\npnpm install\n\n# Start development server\npnpm dev\n\n# Run tests\npnpm test\n```\n\n## Project Structure\n\n```\n/\n├── src/                    # Next.js application source\n│   ├── app/               # App Router pages and API routes\n│   ├── components/        # React components\n│   ├── hooks/             # Custom React hooks\n│   ├── lib/               # Utilities and helpers\n│   ├── server/            # Server-side code\n│   └── context/           # React context providers\n├── packages/              # Monorepo packages\n│   ├── chat-contract/     # Zod schemas for chat API\n│   ├── chat-data/         # Data layer with MiniSearch\n│   ├── chat-orchestrator/ # OpenAI integration\n│   ├── chat-next-api/     # API route handlers\n│   ├── chat-next-ui/      # Chat UI components\n│   ├── chat-preprocess-cli/ # Data preprocessing CLI\n│   ├── github-data/       # GitHub API integration\n│   └── test-support/      # Test fixtures and utilities\n├── infra/cdk/            # AWS CDK infrastructure\n├── generated/            # Preprocessed chat embeddings\n└── e2e/                  # Playwright E2E tests\n```\n\n## Documentation\n\nComprehensive documentation is available in the [docs/](docs/) folder:\n\n- [Getting Started](docs/getting-started/) - Installation, development, and commands\n- [Architecture](docs/architecture/) - System design and infrastructure\n- [Features](docs/features/) - Chat, blog, projects, and authentication\n- [Configuration](docs/configuration/) - Environment variables and secrets\n- [Deployment](docs/deployment/) - CI/CD and production deployment\n- [Testing](docs/testing/) - E2E testing and chat evaluations\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `pnpm dev` | Start development server with Turbopack |\n| `pnpm build` | Build for production (OpenNext + CDK) |\n| `pnpm lint` | Run TypeScript and ESLint checks |\n| `pnpm test` | Run Playwright E2E tests |\n| `pnpm chat:preprocess` | Generate chat embeddings |\n| `pnpm chat:evals` | Run chat quality evaluations |\n\n## License\n\nPrivate repository.",
      "embeddingId": "portfolio"
    },
    {
      "id": "utils",
      "slug": "utils",
      "name": "utils",
      "githubUrl": "https://github.com/Volpestyle/utils",
      "oneLiner": "A personal desktop utilities project aiming to cover a wide range of tools in one place.",
      "description": "A solo, personal project centered on desktop utilities. The README states the scope as 'desktop utilities for everything,' indicating a broad toolkit rather than a single specialized app. The repository appears to describe a general, multi-tool utility collection without documenting a specific tech stack.",
      "bullets": [
        "Defined project scope in the README as 'desktop utilities for everything' for the 'utils' repository (personal project).",
        "Presents a broad, multipurpose desktop utilities concept rather than a single focused tool.",
        "desktop utilities for everything"
      ],
      "impactSummary": "Communicates a broad scope for a desktop utilities suite within a single repository.",
      "sizeOrScope": "solo/personal side project",
      "techStack": [],
      "languages": [
        "Python",
        "Cython",
        "C",
        "Shell",
        "Swift",
        "Roff",
        "PowerShell",
        "JavaScript",
        "Xonsh",
        "HTML"
      ],
      "tags": [],
      "context": {
        "type": "personal",
        "organization": "self",
        "role": "developer",
        "timeframe": {
          "start": "2026-01-07",
          "end": "2026-01-07"
        }
      },
      "contextType": "personal",
      "readme": "desktop utilities for everything",
      "embeddingId": "utils"
    },
    {
      "id": "vuhlp-code",
      "slug": "vuhlp-code",
      "name": "vuhlp-code",
      "githubUrl": "https://github.com/Volpestyle/vuhlp-code",
      "oneLiner": "Local-first, graph-based orchestration for autonomous AI agents that runs on your machine. A monorepo platform coordinating multi-provider agents through graph workflows with full observability.",
      "description": "Vuhlp is a monorepo platform that orchestrates multiple coding agents in user-defined graph workflows, with nodes representing autonomous agents and edges representing explicit handoffs. It emphasizes local-first privacy, keeping runs, logs, and artifacts on-device, while offering full observability of prompts, tool calls, outputs, and artifacts. The project supports multi-provider orchestration (OpenAI, Anthropic, Google, etc.) and includes features like loop safety and multi-turn streaming via local forks for Codex and Gemini. It comprises a daemon runtime (Express + WebSocket), a React UI, provider adapters, and a mobile companion (Expo/React Native).",
      "bullets": [
        "Implemented graph-first workflows where nodes are autonomous agents and edges define data handoffs.",
        "Enforced local-first privacy by running logs and artifacts on the user's machine.",
        "Built full observability: logging of prompts, tool calls, outputs, and artifacts.",
        "Added loop safety with stall-detection to pause runs instead of letting them hang.",
        "Integrated multi-provider orchestration across OpenAI, Anthropic, and Google Vertex AI adapters."
      ],
      "impactSummary": "A privacy-preserving, graph-first platform for orchestrating autonomous AI agents with end-to-end observability and streaming, usable on a developer’s local machine.",
      "sizeOrScope": "Monorepo with 5+ packages (daemon, UI, providers, mobile); targets local-first, single-user development and testing of multi-provider agent workflows.",
      "techStack": [
        "Node.js",
        "Express",
        "WebSocket (WS)",
        "React",
        "React Native",
        "Expo",
        "pnpm",
        "TypeScript",
        "Codex (local forks)",
        "Gemini (local forks)",
        "Claude Code",
        "Codex",
        "Gemini"
      ],
      "languages": [
        "TypeScript",
        "CSS",
        "JavaScript",
        "HTML"
      ],
      "tags": [
        "local-first",
        "graph-first",
        "ai-agent-orchestration",
        "multi-provider",
        "observability",
        "loop-safety",
        "streaming",
        "CLI-patches",
        "monorepo",
        "privacy",
        "AI agent orchestration",
        "Workflow graphs",
        "Graph-based workflows",
        "Local-first privacy",
        "Node.js",
        "Node",
        "NodeJS",
        "Express.js",
        "ExpressJS",
        "React",
        "ReactJS",
        "React.js",
        "Expo",
        "React Native",
        "RN",
        "pnpm",
        "WebSocket",
        "WS",
        "Claude Code",
        "ClaudeCode",
        "Codex",
        "Codex CLI",
        "Gemini",
        "Gemini CLI",
        "OpenAI",
        "OpenAI API",
        "Anthropic",
        "Anthropic API",
        "Google",
        "Vertex AI",
        "Google Cloud",
        "Google AI",
        "HTTP",
        "WebSocket API"
      ],
      "context": {
        "type": "personal",
        "organization": "Vuhlp Agent Platform (personal project)",
        "role": "Developer and architect",
        "timeframe": {
          "start": "2023-01-01",
          "end": "2026-01-24"
        }
      },
      "contextType": "personal",
      "readme": "# Vuhlp Agent Platform\n\n> **Local-first, graph-based orchestration for autonomous AI agents.**\n\nVuhlp is a monorepo platform designed to orchestrate multiple coding agents (OpenAI, Anthropic, Google, etc.) in user-defined workflows. Workflows are graphs: nodes are autonomous agents and edges are explicit handoffs.\n\n## Core Philosophy\n\n- **Graph-First**: Workflows are directed graphs. Nodes and edges define data flow.\n- **Local-First Privacy**: Runs, logs, and artifacts live on your machine.\n- **Agent Autonomy**: Nodes can work independently; an orchestrator node can coordinate.\n- **Full Observability**: Prompts, tool calls, outputs, and artifacts are logged.\n- **Loop Safety**: Stall detection pauses runs instead of hard-capping them.\n\n## Quickstart\n\n### Prerequisites\n- **Node.js**: 25+\n- **pnpm**: 9.x (see `package.json`)\n- Provider CLIs (optional but recommended): Claude Code, Codex, Gemini\n\n### Install\n\n```sh\npnpm install\n```\n\n### Run the daemon\n\n```sh\npnpm dev\n```\n\nDaemon defaults:\n- HTTP: http://localhost:4000\n- WebSocket: ws://localhost:4000/ws\n\n### Run the UI (dev)\n\n```sh\npnpm --filter @vuhlp/ui dev\n```\n\nOpen the UI at http://localhost:5173\n\n## Project Structure\n\n- **`packages/daemon`**: Runtime (Express + WS) that manages runs, nodes, and events.\n- **`packages/ui`**: React UI (graph editor + inspector).\n- **`packages/contracts`**: Shared TypeScript types and JSON schemas.\n- **`packages/shared`**: Shared utilities (API client, logging, UI helpers).\n- **`packages/providers`**: Provider adapters and local CLI forks.\n- **`packages/mobile`**: Mobile companion app (Expo / React Native).\n\n## CLI Patches for Orchestration\n\nTo support true multi-turn streaming, Vuhlp uses local forks:\n- **Codex**: `packages/providers/codex` (submodule) with `codex vuhlp` JSONL stdin/stdout.\n- **Gemini**: `packages/providers/gemini-cli` (submodule) with stream-json stdin.\n\nSee [docs/09-cli-patches.md](docs/09-cli-patches.md) for details and maintenance notes.\n\n## Documentation\n\nThe `docs/` folder is the canonical spec for the current implementation. Start here:\n\n1. [docs/01-product-spec.md](docs/01-product-spec.md)\n2. [docs/05-graph-rules-and-scheduling.md](docs/05-graph-rules-and-scheduling.md)\n3. [docs/12-api.md](docs/12-api.md)",
      "embeddingId": "vuhlp-code"
    },
    {
      "id": "vuhlp-ui",
      "slug": "vuhlp-ui",
      "name": "vuhlp-ui",
      "githubUrl": "https://github.com/Volpestyle/vuhlp-ui",
      "oneLiner": "vuhlp-ui is a monorepo of custom UI components. It centers on the @vuhlp/spinners package—a set of 3D animated spinners built with React Three Fiber for web UIs.",
      "description": "The @vuhlp/spinners package exposes ThinkingSpinner (3D cube with variants: globe, tumble, continuous, assemble), AsciiSpinner (ASCII art 3D renderer with interactive trackball controls), and AsciiRenderer (base component for rendering 3D scenes as ASCII art). It uses pnpm for install/build/dev workflows and targets web UIs.",
      "bullets": [
        "Implemented ThinkingSpinner with four variants: globe, tumble, continuous, and assemble.",
        "Implemented AsciiSpinner: ASCII art 3D renderer with interactive trackball controls.",
        "Implemented AsciiRenderer as the base component for rendering 3D scenes as ASCII art.",
        "Established pnpm-powered install/build/dev workflows and a monorepo structure for the @vuhlp/spinners package.",
        "Built a web-focused React integration using React Three Fiber and Three.js."
      ],
      "impactSummary": "Delivers a reusable 3D and ASCII spinner toolkit for web UIs within a pnpm-powered monorepo.",
      "sizeOrScope": "Monorepo with a dedicated package (@vuhlp/spinners) containing three components for web UI spinners.",
      "techStack": [
        "React",
        "React Three Fiber (R3F)",
        "Three.js",
        "ASCII rendering",
        "pnpm",
        "React Three Fiber",
        "Web"
      ],
      "languages": [
        "TypeScript"
      ],
      "tags": [
        "UI components",
        "3D graphics",
        "ASCII rendering",
        "Chat UI",
        "web",
        "monorepo",
        "component library",
        "3D UI",
        "R3F",
        "React Three Fiber",
        "Three.js",
        "ASCII art",
        "ASCII",
        "web components",
        "pnpm"
      ],
      "context": {
        "type": "personal",
        "organization": "self",
        "role": "side project developer",
        "timeframe": {
          "start": "2024-01-01",
          "end": "2026-01-19"
        }
      },
      "contextType": "personal",
      "readme": "# vuhlp-ui\n\nA component library monorepo for custom UI components.\n\n## Packages\n\n### @vuhlp/spinners\n\n3D animated spinner components built with React Three Fiber.\n\n- **ThinkingSpinner** - Small 3D cube animation for chat UI with multiple variants (globe, tumble, continuous, assemble)\n- **AsciiSpinner** - ASCII art 3D renderer with interactive trackball controls\n- **AsciiRenderer** - Base component for rendering 3D scenes as ASCII art\n\n## Installation\n\n```bash\npnpm install\n```\n\n## Build\n\n```bash\npnpm build\n```\n\n## Development\n\n```bash\npnpm dev\n```",
      "embeddingId": "vuhlp-ui"
    },
    {
      "id": "y2k-nostalgic-futurism",
      "slug": "y2k-nostalgic-futurism",
      "name": "y2k-nostalgic-futurism",
      "githubUrl": "https://github.com/Volpestyle/y2k-nostalgic-futurism",
      "oneLiner": "A personal, y2k-inspired sandbox for playful experiments in retro-futurist ideas. A space to tinker with nostalgic aesthetics and concepts.",
      "description": "Grounded in a y2k-inspired sandbox concept, this project serves as a personal playground for exploring retro-futurist ideas. It emphasizes conceptual exploration and aesthetic experimentation rather than feature development. The README communicates the project identity as a y2k-inspired sandbox, reinforcing its role as a lightweight, self-directed exploration space.",
      "bullets": [
        "Defined and documented a y2k-inspired concept to guide sandbox experiments.",
        "Framed as a solo, personal project focused on exploring nostalgic aesthetics.",
        "Positioned as a flexible playground for future experiments without a formal feature roadmap."
      ],
      "impactSummary": "A personal exploration space for y2k-inspired ideas that can seed future experiments.",
      "sizeOrScope": "Solo, personal sandbox; no public user base yet.",
      "techStack": [
        "n/a"
      ],
      "languages": [
        "TypeScript",
        "Python",
        "HTML",
        "JavaScript",
        "CSS",
        "Shell",
        "Mermaid",
        "Dockerfile"
      ],
      "tags": [
        "personal",
        "y2k",
        "nostalgia",
        "sandbox",
        "aesthetics"
      ],
      "context": {
        "type": "personal",
        "organization": "Self",
        "role": "Creator/Experimenter",
        "timeframe": {
          "start": "2025-12-29",
          "end": "2026-01-04"
        }
      },
      "contextType": "personal",
      "readme": "y2k inspired sandbox",
      "embeddingId": "y2k-nostalgic-futurism"
    },
    {
      "id": "yt-expert",
      "slug": "yt-expert",
      "name": "yt-expert",
      "githubUrl": "https://github.com/Volpestyle/yt-expert",
      "oneLiner": "yt-expert is a local-first YouTube channel expert that ingests channel data into offline packs and answers questions using a local LLM RAG pipeline with timestamped citations.",
      "description": "A monorepo containing a Python core package and a small demo API/UI that demonstrates offline YouTube channel packs and local, question-answering workflows. It ingests YouTube channel data into packs and exposes a demo API + UI to interact with the core. The system supports a configurable LLM provider via environment variables and YouTube cookies for blocked content, enabling offline, local-first operation powered by whisper for transcripts and embeddings_local for local embeddings.",
      "bullets": [
        "Ingest YouTube channel data into offline packs (e.g., yt-expert ingest channel --channel-id UCxxxxxxxxxxxxxxxxxxxxxx --recent 5 --pack-name \"my-pack\").",
        "Answer questions with a local retrieve-augment-generation (RAG) pipeline and timestamped citations for verifiable results.",
        "Provide a runnable demo API + UI that interact with the core, accessible by default at http://localhost:8000 (configurable via PUBLIC_API_BASE).",
        "Support configurable LLM backends via environment variables (YTEXPERT_LLM_PROVIDER, YTEXPERT_BEDROCK_LLM_MODEL_ID, AWS_REGION).",
        "Enable YouTube cookies support through YTEXPERT_COOKIES_FILE or YTEXPERT_COOKIES_SECRET_ARN (legacy DEMO_API_YTDLP_COOKIES* env vars are honored)."
      ],
      "impactSummary": "Enables offline YouTube channel data packs with a configurable, local LLM-backed Q&A flow and timestamped citations, demonstrated via a runnable API/UI.",
      "sizeOrScope": "Monorepo with core library and demo API/UI; smallMaintainer team; target users are local developers running the demo; packs support multi-channel ingestion for local/offline use.",
      "techStack": [
        "Python",
        "pnpm",
        "pip",
        "venv",
        "whisper",
        "embeddings_local",
        "yt-dlp / YTDLP",
        "bedrock",
        "Anthropic Claude",
        "AWS",
        "YouTube cookies",
        "yt-dlp",
        "YTDLP",
        "Claude-3-sonnet-20240229-v1:0",
        "AWS_REGION"
      ],
      "languages": [
        "Python",
        "Svelte",
        "CSS",
        "TypeScript",
        "HCL",
        "Mermaid",
        "Shell",
        "HTML",
        "JavaScript",
        "Makefile"
      ],
      "tags": [
        "local-first",
        "offline",
        "RAG",
        "timestamped-citations",
        "YouTube",
        "LLMs",
        "demo",
        "cookies",
        "monorepo",
        "AI/ML (LLMs)",
        "Cloud / AWS",
        "yt-expert",
        "YTEXPERT",
        "pnpm",
        "pip",
        "venv",
        "whisper",
        "embeddings_local",
        "yt-dlp",
        "YTDLP",
        "bedrock",
        "Anthropic Claude",
        "Claude-3-sonnet-20240229-v1:0",
        "AWS",
        "AWS_REGION"
      ],
      "context": {
        "type": "oss",
        "organization": "yt-expert (open-source project)",
        "role": "maintainer/developer",
        "timeframe": {
          "start": "2023-01-01",
          "end": "2026-01-02"
        }
      },
      "contextType": "oss",
      "readme": "# yt-expert — Monorepo (core + demo UI/API)\n\nThis repo hosts the **yt-expert** Python package plus a small demo API/UI that consumes it.\n\n- Core package: `src/yt_expert/`\n- Docs: `src/docs/`\n- Demo API: `services/demo-api`\n- Demo UI: `apps/demo-ui`\n\n---\n\n## Core quickstart (local)\n\n```bash\npython -m venv .venv\nsource .venv/bin/activate\npip install -U pip\npip install -e \".[dev,whisper,embeddings_local]\"\n\n# Ingest\nyt-expert ingest channel --channel-id UCxxxxxxxxxxxxxxxxxxxxxx --recent 5 --pack-name \"my-pack\"\n\n# Serve API\nyt-expert serve --host 0.0.0.0 --port 8000\n```\n\nSee `src/README.md` for the full core README.\n\n---\n\n## Demo app (API + UI)\n\n```bash\npnpm demo:api:setup\npnpm demo:api\n```\n\n```bash\npnpm demo:ui:install\npnpm demo:ui\n```\n\nThe UI talks to the demo API at `http://localhost:8000` by default. Set `PUBLIC_API_BASE` if your API runs elsewhere.\n\n### LLM settings\n\nThe demo API now uses **yt-expert** settings. Configure via `YTEXPERT_*` env vars, e.g.:\n\n```bash\nexport YTEXPERT_LLM_PROVIDER=bedrock\nexport YTEXPERT_BEDROCK_LLM_MODEL_ID=anthropic.claude-3-sonnet-20240229-v1:0\nexport AWS_REGION=us-east-1\n```\n\nIf `YTEXPERT_LLM_PROVIDER` is `none` (default), the API uses a no-op model that returns the most relevant context.\n\n### YouTube cookies\n\nIf YouTube blocks yt-dlp, provide cookies:\n\n- `YTEXPERT_COOKIES_FILE=/path/to/cookies.txt`, or\n- `YTEXPERT_COOKIES_SECRET_ARN=...`\n\nLegacy demo env vars (`DEMO_API_YTDLP_COOKIES*`) are still honored.",
      "embeddingId": "yt-expert"
    }
  ]
}